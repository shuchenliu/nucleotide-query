import uuid

from rest_framework import status
from rest_framework.parsers import JSONParser
from rest_framework.response import Response
from rest_framework.views import APIView

from api.genome.reference import GenomeReference
from api.models import SearchTerm, Match
from api.serializers import SearchTermSerializer, MatchSerializer

import re2 as re

class QueryView(APIView):
    parser_classes = [JSONParser]

    sequence, sequence_id = GenomeReference.get()

    def post(self, request):

        # use serializer to conduct validation
        serializer = SearchTermSerializer(data=request.data)

        # handle invalid requests
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


        # Try match with db
        # todo:
        #  1. cache layer redis
        #  2. celery for delayed db writes
        #  3. pagination
        #  4. add atomic

        pattern = serializer.validated_data['pattern']

        try:
            search_term = SearchTerm.objects.get(pattern=pattern)
        except SearchTerm.DoesNotExist:

            # create SearchTerm record
            search_term = SearchTerm(pattern=pattern, sequence_id=self.sequence_id)
            search_term.save()

            # bulk saving to db in batch:
            for batch in self.get_match_stream(pattern):

                # calculate ids
                match_ids = [
                    self.compute_match_id(start, end)
                    for start, end in batch
                ]

                # bulk create
                match_records = [
                    Match(id=mid, start=start, end=end, sequence_id=self.sequence_id)
                    for mid, (start, end) in zip(match_ids, batch)
                ]

                Match.objects.bulk_create(match_records, ignore_conflicts=True, batch_size=500)

                # add many-to-many relationships to search_term
                search_term.matches.add(*match_ids)

        return self.prepare_response(search_term)


    def prepare_response(self, search_term: SearchTerm):
        matches = search_term.matches.all()
        if not matches.exists():
            return Response({
                "details": "No matches found",
            }, status=status.HTTP_404_NOT_FOUND)

        serializer = MatchSerializer(matches, many=True)
        return Response(serializer.data, status=status.HTTP_200_OK)



    def compute_match_id(self, start: int, end: int) -> uuid.UUID:
        # predefined UUID, generated by uuid.uuid4()
        name_space = uuid.UUID('7c8d57cf-ff50-4a5b-a5fe-8710de4a2617')
        payload = f"{self.sequence_id}:{start}:{end}"
        return uuid.uuid5(name_space, payload)


    def get_match_stream(self, term, chunk_size=1000) :
        regex_pattern = re.compile(term)
        batch = []

        for matched in regex_pattern.finditer(self.sequence):
            batch.append((matched.start(), matched.end()))
            if len(batch)  == chunk_size:
                yield batch
                batch = []

        if batch:
            yield batch






